{"cells":[{"cell_type":"code","execution_count":787,"id":"1057c463-e1f3-4a42-9e5d-1be0045ca943","metadata":{"id":"1057c463-e1f3-4a42-9e5d-1be0045ca943","executionInfo":{"status":"ok","timestamp":1756140970689,"user_tz":420,"elapsed":48,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"outputs":[],"source":["#Import libraries\n","import pandas as pd\n","import numpy as np\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ldSRvjIZCUw","executionInfo":{"status":"ok","timestamp":1756140971445,"user_tz":420,"elapsed":759,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"483b6603-beee-4a6b-e2e6-70e9bd212cf7"},"id":"8ldSRvjIZCUw","execution_count":788,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":789,"id":"4116a55d-d0d3-42dd-b400-a5abe4077e13","metadata":{"id":"4116a55d-d0d3-42dd-b400-a5abe4077e13","executionInfo":{"status":"ok","timestamp":1756140971448,"user_tz":420,"elapsed":7,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"outputs":[],"source":["import pandas as pd\n","\n","#Read input data\n","train_data = pd.read_csv('/content/drive/MyDrive/ML/titanic-ml-project/data/processed/train.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/ML/titanic-ml-project/data/processed/test.csv')\n"]},{"cell_type":"code","execution_count":790,"id":"pGx750lPk-qx","metadata":{"id":"pGx750lPk-qx","executionInfo":{"status":"ok","timestamp":1756140971482,"user_tz":420,"elapsed":22,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"outputs":[],"source":["# Define features and target variable\n","X_train = train_data.drop('Survived', axis=1)\n","Y_train = train_data['Survived']\n","\n","X_test = test_data.drop('Survived', axis=1)\n","Y_test = test_data['Survived']"]},{"cell_type":"markdown","metadata":{"id":"725b19db-8f79-4f42-926f-a4480afb6d68"},"source":["## Decision Tree Classifier"],"id":"725b19db-8f79-4f42-926f-a4480afb6d68"},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report\n","\n","# Load dataset\n","data = load_iris()\n","X, y = data.data, data.target\n","\n","# Initialize the Decision Tree Classifier with optimized parameters\n","dt = DecisionTreeClassifier(max_depth=18, max_features='sqrt', min_samples_leaf=0.01, min_samples_split=0.061, random_state=42)\n","\n","# Train the model\n","dt.fit(X_train, Y_train)\n","\n","# Make predictions on the test set\n","Y_dt_opt_pred = dt.predict(X_test)\n","\n","target_names = ['Didnt Survived', 'Survived']\n","print(classification_report(Y_test, Y_dt_opt_pred, target_names=target_names))\n","\n","# Evaluate the model\n","accuracy = dt.score(X_test, Y_test)\n","print(\"Test accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1x3x1N8BLmp","executionInfo":{"status":"ok","timestamp":1756141031565,"user_tz":420,"elapsed":32,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"f744f0f7-7660-44bd-9fd5-d8f50f251ef3"},"id":"P1x3x1N8BLmp","execution_count":799,"outputs":[{"output_type":"stream","name":"stdout","text":["                precision    recall  f1-score   support\n","\n","Didnt Survived       0.92      0.98      0.95       266\n","      Survived       0.97      0.86      0.91       152\n","\n","      accuracy                           0.94       418\n","     macro avg       0.95      0.92      0.93       418\n","  weighted avg       0.94      0.94      0.94       418\n","\n","Test accuracy: 0.937799043062201\n"]}]},{"cell_type":"markdown","source":["## HistGradientBoostingClassifier"],"metadata":{"id":"wI0Spz1kkMYM"},"id":"wI0Spz1kkMYM"},{"cell_type":"code","source":["from sklearn.ensemble import HistGradientBoostingClassifier\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Initialize and fit the model with the best parameters\n","model = HistGradientBoostingClassifier(\n","    min_samples_leaf=10,\n","    max_iter=500,\n","    max_depth=5,\n","    max_bins=32,\n","    learning_rate=0.1,\n","    early_stopping=True\n",")\n","model.fit(X_train, Y_train)\n","\n","# Make predictions\n","Y_pred = model.predict(X_test)\n","\n","# Create a DataFrame to compare actual and predicted values\n","diff_df = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\n","print(diff_df)\n","\n","# Compute the confusion matrix\n","conf_matrix = confusion_matrix(Y_test, Y_pred)\n","print(conf_matrix)\n","\n","# Compute the classification report\n","target_names = ['Didnt Survived', 'Survived']\n","print(classification_report(Y_test, Y_pred, target_names=target_names))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ro1CHOpViogM","executionInfo":{"status":"ok","timestamp":1756141035915,"user_tz":420,"elapsed":176,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"28c62e80-91c0-440a-ac31-ca3948af99e0"},"id":"ro1CHOpViogM","execution_count":800,"outputs":[{"output_type":"stream","name":"stdout","text":["     Actual  Predicted\n","0         0          0\n","1         1          0\n","2         0          0\n","3         0          0\n","4         1          0\n","..      ...        ...\n","413       0          0\n","414       1          1\n","415       0          0\n","416       0          0\n","417       0          0\n","\n","[418 rows x 2 columns]\n","[[261   5]\n"," [ 26 126]]\n","                precision    recall  f1-score   support\n","\n","Didnt Survived       0.91      0.98      0.94       266\n","      Survived       0.96      0.83      0.89       152\n","\n","      accuracy                           0.93       418\n","     macro avg       0.94      0.91      0.92       418\n","  weighted avg       0.93      0.93      0.92       418\n","\n"]}]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"ZCGTAdvomb_e"},"id":"ZCGTAdvomb_e"},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Define the XGBoost model with the specified hyperparameters\n","model = xgb.XGBClassifier(\n","    subsample=1,\n","    reg_lambda=0,\n","    reg_alpha=0,\n","    n_estimators=500,\n","    max_depth=3,\n","    learning_rate=0.1,\n","    gamma=1,\n","    colsample_bytree=0.8,\n","    eval_metric='mlogloss'  # Change this based on your task (e.g., 'logloss' for binary classification)\n",")\n","\n","# Fit the model on the training data\n","model.fit(X_train, Y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(Y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","# Generate and print the classification report\n","report = classification_report(Y_test, y_pred)\n","print(\"Classification Report:\")\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jh4ckX3bfIC2","executionInfo":{"status":"ok","timestamp":1756141041842,"user_tz":420,"elapsed":152,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"108f8ad5-4668-4ef7-983f-7f0ffcbb3873"},"id":"Jh4ckX3bfIC2","execution_count":801,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.90\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.97      0.92       266\n","           1       0.94      0.76      0.84       152\n","\n","    accuracy                           0.90       418\n","   macro avg       0.91      0.87      0.88       418\n","weighted avg       0.90      0.90      0.89       418\n","\n"]}]},{"cell_type":"markdown","source":["## Random Forests"],"metadata":{"id":"alLQFuoYmS3c"},"id":"alLQFuoYmS3c"},{"cell_type":"markdown","source":["## Tunning"],"metadata":{"id":"suZRS_QoB5Ib"},"id":"suZRS_QoB5Ib"},{"cell_type":"markdown","source":["#### DecisionTreeClassifier Tunning"],"metadata":{"id":"McjBo9LEed_q"},"id":"McjBo9LEed_q"},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report\n","from scipy.stats import randint, uniform\n","\n","# Assuming X_train, X_test, Y_train, Y_test are already loaded and split\n","\n","# Define the parameter distribution for hyperparameter tuning with RandomizedSearchCV\n","param_dist = {\n","    'max_depth': randint(1, 21),  # Randomly sample depths from 1 to 20\n","    'min_samples_split': uniform(0.01, 0.5),  # Uniform distribution between 0.01 and 0.5\n","    'min_samples_leaf': uniform(0.01, 0.5),  # Uniform distribution between 0.01 and 0.5\n","    'max_features': ['auto', 'sqrt', 'log2']  # Example values for max_features\n","}\n","\n","# Initialize the Decision Tree Classifier\n","dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n","\n","# Use RandomizedSearchCV for hyperparameter tuning with cross-validation\n","random_search = RandomizedSearchCV(estimator=dt, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n","random_search.fit(X_train, Y_train)\n","\n","# Best parameters\n","best_params = random_search.best_params_\n","print(\"Best parameters (RandomizedSearchCV):\")\n","for param, value in best_params.items():\n","    if param in ['min_samples_split', 'min_samples_leaf']:\n","        print(f\"{param}: {round(value, 3)}\")\n","    else:\n","        print(f\"{param}: {value}\")\n","\n","# Define a grid of hyperparameters for GridSearchCV around the best parameters\n","param_grid = {\n","    'max_depth': [best_params['max_depth']-2, best_params['max_depth']-1, best_params['max_depth'], best_params['max_depth']+1, best_params['max_depth']+2],\n","    'min_samples_split': [max(0.01, best_params['min_samples_split']-0.05), round(best_params['min_samples_split'], 3), min(0.5, best_params['min_samples_split']+0.05)],\n","    'min_samples_leaf': [max(0.01, best_params['min_samples_leaf']-0.05), round(best_params['min_samples_leaf'], 3), min(0.5, best_params['min_samples_leaf']+0.05)],\n","    'max_features': [best_params['max_features']]\n","}\n","\n","# Use GridSearchCV for a more exhaustive search in the promising region\n","grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, Y_train)\n","\n","# Best parameters\n","best_params_grid = grid_search.best_params_\n","print(\"\\nBest parameters (GridSearchCV):\")\n","for param, value in best_params_grid.items():\n","    if param in ['min_samples_split', 'min_samples_leaf']:\n","        print(f\"{param}: {round(value, 3)}\")\n","    else:\n","        print(f\"{param}: {value}\")\n","\n","# Make predictions on the test set using the best estimator\n","Y_dt_opt_pred = grid_search.best_estimator_.predict(X_test)\n","\n","# Define target names for the classification report\n","target_names = ['Did not Survive', 'Survived']\n","\n","# Generate and print the classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(Y_test, Y_dt_opt_pred, target_names=target_names))\n","\n","# Evaluate the model's accuracy\n","accuracy = grid_search.best_estimator_.score(X_test, Y_test)\n","print(\"\\nTest accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRb1MgZRAwL8","executionInfo":{"status":"ok","timestamp":1756140975745,"user_tz":420,"elapsed":3398,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"f5531d85-a343-4085-d760-6955e26c5a3b"},"id":"ZRb1MgZRAwL8","execution_count":794,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n","170 fits failed out of a total of 500.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","170 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1382, in wrapper\n","    estimator._validate_params()\n","  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 436, in _validate_params\n","    validate_parameter_constraints(\n","  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n","    raise InvalidParameterError(\n","sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.73067604 0.66449689 0.71382211 0.66449689 0.66449689\n"," 0.66449689 0.61616345 0.63414098        nan 0.66449689 0.66449689\n"," 0.66449689 0.66449689 0.66449689 0.66449689 0.72955244        nan\n","        nan        nan 0.61616345 0.66449689 0.61616345 0.66449689\n"," 0.61616345 0.61616345 0.66449689        nan        nan        nan\n"," 0.66449689 0.61616345 0.61616345 0.71272362        nan 0.66449689\n"," 0.66449689        nan 0.61616345        nan 0.66449689        nan\n"," 0.61616345 0.61616345        nan 0.66449689        nan 0.61616345\n"," 0.66449689 0.61616345 0.66449689 0.61616345 0.61616345        nan\n"," 0.61616345 0.61616345        nan 0.77336639        nan 0.61616345\n","        nan 0.61616345 0.66449689 0.61616345 0.66449689 0.66449689\n"," 0.66449689 0.61616345        nan        nan 0.66449689 0.66449689\n"," 0.66449689 0.66449689        nan        nan        nan        nan\n"," 0.61616345 0.71944009        nan 0.61616345        nan        nan\n"," 0.66449689        nan        nan 0.61616345        nan 0.68460862\n","        nan 0.66449689 0.66449689        nan        nan        nan\n"," 0.66449689 0.66449689 0.66449689 0.61616345]\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters (RandomizedSearchCV):\n","max_depth: 20\n","max_features: sqrt\n","min_samples_leaf: 0.015\n","min_samples_split: 0.061\n","\n","Best parameters (GridSearchCV):\n","max_depth: 18\n","max_features: sqrt\n","min_samples_leaf: 0.01\n","min_samples_split: 0.061\n","\n","Classification Report:\n","                 precision    recall  f1-score   support\n","\n","Did not Survive       0.84      1.00      0.92       266\n","       Survived       1.00      0.68      0.81       152\n","\n","       accuracy                           0.88       418\n","      macro avg       0.92      0.84      0.86       418\n","   weighted avg       0.90      0.88      0.88       418\n","\n","\n","Test accuracy: 0.8827751196172249\n"]}]},{"cell_type":"markdown","source":["#### XGBoost Tunning"],"metadata":{"id":"GDsnfIVwfpXv"},"id":"GDsnfIVwfpXv"},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from scipy.stats import uniform, randint\n","import numpy as np\n","\n","# Define the hyperparameter search space using continuous distributions\n","param_distributions = {\n","    'max_depth': randint(3, 10),  # Random integers between 3 and 9\n","    'learning_rate': uniform(0.01, 0.99),  # Uniform distribution from 0.01 to 1\n","    'n_estimators': randint(50, 501),  # Random integers between 50 and 500\n","    'gamma': uniform(0, 1),  # Uniform distribution from 0 to 1\n","    'subsample': uniform(0.5, 0.5),  # Uniform distribution from 0.5 to 1\n","    'colsample_bytree': uniform(0.5, 0.5),  # Uniform distribution from 0.5 to 1\n","    'reg_alpha': uniform(0, 1),  # Uniform distribution from 0 to 1\n","    'reg_lambda': uniform(0, 1)  # Uniform distribution from 0 to 1\n","}\n","\n","# Define the model and the cross-validation strategy\n","model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Perform randomized search with cross-validation\n","random_search = RandomizedSearchCV(\n","    model,\n","    param_distributions,\n","    cv=cv,\n","    n_iter=30,  # Increased iterations for better exploration\n","    random_state=42,\n","    scoring='f1_macro',\n","    n_jobs=-1,  # Use all available cores\n","    verbose=1    # Monitor progress\n",")\n","\n","random_search.fit(X_train, Y_train)\n","\n","# Round the best parameters from RandomizedSearchCV\n","best_params_random = {k: round(v, 2) if isinstance(v, float) else v for k, v in random_search.best_params_.items()}\n","print(\"Best parameters from RandomizedSearchCV (rounded):\", best_params_random)\n","print(\"Best score from RandomizedSearchCV:\", random_search.best_score_)\n","\n","# Define a narrower grid around the best parameters found\n","param_grid = {\n","    'max_depth': [best_params_random['max_depth'] - 1, best_params_random['max_depth'], best_params_random['max_depth'] + 1],\n","    'learning_rate': [round(best_params_random['learning_rate'] - 0.05, 3),\n","                      round(best_params_random['learning_rate'], 3),\n","                      round(best_params_random['learning_rate'] + 0.05, 3)],\n","    'n_estimators': [best_params_random['n_estimators'] - 50, best_params_random['n_estimators'], best_params_random['n_estimators'] + 50],\n","    'gamma': [round(best_params_random['gamma'] - 0.1, 3),\n","              round(best_params_random['gamma'], 3),\n","              round(best_params_random['gamma'] + 0.1, 3)],\n","    'subsample': [round(best_params_random['subsample'], 3)],\n","    'colsample_bytree': [round(best_params_random['colsample_bytree'], 3)],\n","    'reg_alpha': [round(best_params_random['reg_alpha'], 3)],\n","    'reg_lambda': [round(best_params_random['reg_lambda'], 3)]\n","}\n","\n","# Perform grid search with cross-validation\n","grid_search = GridSearchCV(\n","    model,\n","    param_grid,\n","    cv=cv,\n","    scoring='f1_macro',\n","    n_jobs=-1,  # Use all available cores\n","    verbose=1    # Monitor progress\n",")\n","\n","grid_search.fit(X_train, Y_train)\n","\n","# Round the best parameters from GridSearchCV\n","best_params_grid = {k: round(v, 2) if isinstance(v, float) else v for k, v in grid_search.best_params_.items()}\n","print(\"Best parameters from GridSearchCV (rounded):\", best_params_grid)\n","print(\"Best score from GridSearchCV:\", grid_search.best_score_)\n","\n","# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","\n","print(\"Test set accuracy:\", accuracy_score(Y_test, y_pred))\n","print(\"Test set classification report:\")\n","print(classification_report(Y_test, y_pred))\n","print(\"Test set confusion matrix:\")\n","print(confusion_matrix(Y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"qiY5FEHKp_1A","executionInfo":{"status":"error","timestamp":1756140977428,"user_tz":420,"elapsed":1681,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}},"outputId":"c2d278ab-3a4f-4a3f-a207-4fbd8c65142b"},"id":"qiY5FEHKp_1A","execution_count":795,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1849932477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Round the best parameters from RandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from scipy.stats import uniform, randint\n","import numpy as np\n","\n","def xgboost_hyperparameter_tuning(X_train, Y_train, X_test, Y_test):\n","    # Define the hyperparameter search space using continuous distributions\n","    param_distributions = {\n","        'max_depth': randint(3, 10),\n","        'learning_rate': uniform(0.01, 0.99),\n","        'n_estimators': randint(50, 501),\n","        'gamma': uniform(0, 1),\n","        'subsample': uniform(0.1, 0.9),\n","        'colsample_bytree': uniform(0.1, 0.9),\n","        'reg_alpha': uniform(0, 1),\n","        'reg_lambda': uniform(0, 1)\n","    }\n","\n","    # Define the model and the cross-validation strategy\n","    model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    # Perform randomized search with cross-validation\n","    random_search = RandomizedSearchCV(\n","        model,\n","        param_distributions,\n","        cv=cv,\n","        n_iter=50,\n","        random_state=42,\n","        scoring='f1_macro',\n","        n_jobs=-1,\n","        verbose=1\n","    )\n","\n","    random_search.fit(X_train, Y_train)\n","\n","    # Round the best parameters from RandomizedSearchCV\n","    best_params_random = {k: round(v, 2) if isinstance(v, float) else v for k, v in random_search.best_params_.items()}\n","    print(\"Best parameters from RandomizedSearchCV (rounded):\", best_params_random)\n","    print(\"Best score from RandomizedSearchCV:\", random_search.best_score_)\n","\n","    # Define a narrower grid around the best parameters found\n","    param_grid = {\n","        'max_depth': [best_params_random['max_depth'] - 1, best_params_random['max_depth'], best_params_random['max_depth'] + 1],\n","        'learning_rate': [round(best_params_random['learning_rate'] - 0.05, 3),\n","                          round(best_params_random['learning_rate'], 3),\n","                          round(best_params_random['learning_rate'] + 0.05, 3)],\n","        'n_estimators': [best_params_random['n_estimators'] - 50, best_params_random['n_estimators'], best_params_random['n_estimators'] + 50],\n","        'gamma': [round(best_params_random['gamma'] - 0.1, 3),\n","                  round(best_params_random['gamma'], 3),\n","                  round(best_params_random['gamma'] + 0.1, 3)],\n","        'subsample': [round(best_params_random['subsample'], 3)],\n","        'colsample_bytree': [round(best_params_random['colsample_bytree'], 3)],\n","        'reg_alpha': [round(best_params_random['reg_alpha'], 3)],\n","        'reg_lambda': [round(best_params_random['reg_lambda'], 3)]\n","    }\n","\n","    # Perform grid search with cross-validation\n","    grid_search = GridSearchCV(\n","        model,\n","        param_grid,\n","        cv=cv,\n","        scoring='f1_macro',\n","        n_jobs=-1,\n","        verbose=1\n","    )\n","\n","    grid_search.fit(X_train, Y_train)\n","\n","    # Round the best parameters from GridSearchCV\n","    best_params_grid = {k: round(v, 2) if isinstance(v, float) else v for k, v in grid_search.best_params_.items()}\n","    print(\"Best parameters from GridSearchCV (rounded):\", best_params_grid)\n","    print(\"Best score from GridSearchCV:\", grid_search.best_score_)\n","\n","    # Evaluate the best model on the test set\n","    best_model = grid_search.best_estimator_\n","    y_pred = best_model.predict(X_test)\n","\n","    print(\"Test set accuracy:\", accuracy_score(Y_test, y_pred))\n","    print(\"Test set classification report:\")\n","    print(classification_report(Y_test, y_pred))\n","    print(\"Test set confusion matrix:\")\n","    print(confusion_matrix(Y_test, y_pred))\n","\n","# Assuming X_train, X_test, Y_train, Y_test are already loaded and split\n","xgboost_hyperparameter_tuning(X_train, Y_train, X_test, Y_test)\n"],"metadata":{"id":"aIH_T7B1EDmx","executionInfo":{"status":"aborted","timestamp":1756140977769,"user_tz":420,"elapsed":2,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"id":"aIH_T7B1EDmx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Define the XGBoost model with the specified hyperparameters\n","model = xgb.XGBClassifier(\n","    subsample=0.53,\n","    reg_lambda=0.5,\n","    reg_alpha=0.61,\n","    n_estimators=236,\n","    max_depth=2,\n","    learning_rate=0.16,\n","    gamma=0.71,\n","    colsample_bytree=0.85,\n","    use_label_encoder=False,\n","    eval_metric='mlogloss'  # Change this based on your task (e.g., 'logloss' for binary classification)\n",")\n","\n","# Fit the model on the training data\n","model.fit(X_train, Y_train)\n","\n","# Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(Y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","# Generate and print the classification report\n","report = classification_report(Y_test, y_pred)\n","print(\"Classification Report:\")\n","print(report)\n"],"metadata":{"id":"aVW3aekLv6CY","executionInfo":{"status":"aborted","timestamp":1756140977815,"user_tz":420,"elapsed":7308,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"id":"aVW3aekLv6CY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### HistGradientBoostingClassifier Tunning"],"metadata":{"id":"uRjMy4KRfz_b"},"id":"uRjMy4KRfz_b"},{"cell_type":"code","source":["import numpy as np\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import uniform, randint\n","\n","# Create a synthetic dataset\n","X, Y = make_classification(n_samples=1000, n_features=20, random_state=42)\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# Define the hyperparameter search space using continuous distributions\n","param_dist = {\n","    'learning_rate': uniform(0.01, 1),  # Continuous values between 0.01 and 1\n","    'max_iter': randint(100, 1001),      # Integer values between 100 and 1000\n","    'max_depth': randint(3, 8),          # Integer values between 3 and 7\n","    'min_samples_leaf': randint(1, 11),  # Integer values between 1 and 10\n","    'max_bins': randint(16, 65),         # Integer values between 16 and 64\n","    'early_stopping': [True, False]\n","}\n","\n","# Define the model and the cross-validation strategy\n","model = HistGradientBoostingClassifier(random_state=42)\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Perform randomized search with cross-validation\n","random_search = RandomizedSearchCV(model, param_dist, cv=cv, n_iter=30, random_state=42)\n","random_search.fit(X_train, Y_train)\n","\n","# Print the best parameters and the best score\n","print(\"Best parameters (before rounding):\", random_search.best_params_)\n","print(\"Best score:\", random_search.best_score_)\n","\n","# Round the best parameters to 3 decimal places\n","best_params_rounded = {k: round(v, 3) if isinstance(v, float) else v for k, v in random_search.best_params_.items()}\n","print(\"Best parameters (after rounding):\", best_params_rounded)\n","\n","# Define a smaller parameter grid for RandomizedSearchCV based on the best parameters found\n","grid_param = {\n","    'learning_rate': [best_params_rounded['learning_rate'] - 0.01, best_params_rounded['learning_rate'], best_params_rounded['learning_rate'] + 0.01],\n","    'max_iter': [best_params_rounded['max_iter'] - 100, best_params_rounded['max_iter'], best_params_rounded['max_iter'] + 100],\n","    'max_depth': [best_params_rounded['max_depth'] - 1, best_params_rounded['max_depth'], best_params_rounded['max_depth'] + 1],\n","    'min_samples_leaf': [best_params_rounded['min_samples_leaf'] - 1, best_params_rounded['min_samples_leaf'], best_params_rounded['min_samples_leaf'] + 1],\n","    'max_bins': [best_params_rounded['max_bins'] - 8, best_params_rounded['max_bins'], best_params_rounded['max_bins'] + 8],\n","    'early_stopping': [True, False]\n","}\n","\n","# Perform randomized search again instead of grid search for efficiency\n","random_search_final = RandomizedSearchCV(model, grid_param, cv=cv, n_iter=30, n_jobs=-1, random_state=42)\n","random_search_final.fit(X_train, Y_train)\n","\n","# Print the best parameters and the best score from the final search\n","print(\"Best parameters from final RandomizedSearchCV:\", random_search_final.best_params_)\n","print(\"Best score from final RandomizedSearchCV:\", random_search_final.best_score_)\n","\n","# Evaluate the best model on the test set\n","best_model = random_search_final.best_estimator_\n","test_score = best_model.score(X_test, Y_test)\n","print(\"Test set score:\", test_score)\n"],"metadata":{"id":"oRro950jyZFK","executionInfo":{"status":"aborted","timestamp":1756140977818,"user_tz":420,"elapsed":7305,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"id":"oRro950jyZFK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import HistGradientBoostingClassifier\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Initialize and fit the model with the best parameters\n","model = HistGradientBoostingClassifier(\n","    min_samples_leaf=7,\n","    max_iter=558,\n","    max_depth=4,\n","    max_bins=38,\n","    learning_rate=0.456,\n","    early_stopping=True\n",")\n","model.fit(X_train, Y_train)\n","\n","# Make predictions\n","Y_pred = model.predict(X_test)\n","\n","# Create a DataFrame to compare actual and predicted values\n","diff_df = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\n","print(diff_df)\n","\n","# Compute the confusion matrix\n","conf_matrix = confusion_matrix(Y_test, Y_pred)\n","print(conf_matrix)\n","\n","# Compute the classification report\n","target_names = ['Didnt Survived', 'Survived']\n","print(classification_report(Y_test, Y_pred, target_names=target_names))"],"metadata":{"id":"Iq3piJTjyli2","executionInfo":{"status":"aborted","timestamp":1756140977821,"user_tz":420,"elapsed":7301,"user":{"displayName":"BLADYS OMAR PEREZ CUELLO","userId":"08479378209250619824"}}},"id":"Iq3piJTjyli2","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1HAhS3YbD60KkPHg-GFIefDjna3BVD2mx","timestamp":1755258604703}],"collapsed_sections":["suZRS_QoB5Ib","uRjMy4KRfz_b"]},"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":5}